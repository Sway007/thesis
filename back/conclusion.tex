% !Mode:: "TeX:UTF-8" 
\begin{conclusions}

本文主要针对自动驾驶系统的测试用例，即路况图片的合成技术，围绕对抗生成网络和图像转换技术展开的实证研究。
经过对大量的深度学习模型实验与模型排除后，最后进行的实验数据统计的模型有8个：MUNIT，CycleGAN，EBGAN，AdaIN Style，Deep Photo Style，Fast Photo Style，Fast Neural Transfer，Texture Nets。

在实验的数据统计与总结中，我们提出了3个模型实验结果的比较指标：模型训练时间、FID值和方向盘拐角差。希望通过这3个指标综合、客观的评价比较出每个模型在路况图片转换中的性能优劣。在最终的实验数据以及我们选择的实验模型范围中来看，图像转换技术大类要优于对抗生成网络大类的模型。我们分析原因主要有有两点：

对抗生成网络的性能对训练数据集很敏感，且对数据集图片质量的要求很高，即需要内容数据集和样式数据集的图片内容结果十分接近。而满足要求的数据集往往需要专门的数据集采集工作，成本较高。而图像转换技术主要是对图像的像素色彩和明暗度做修改，所以对数据集的要求没有对抗生成网络的高，且在我们采集的结果数据中，各项指标数据都要优于对抗生成网络。

其次图像转换技术合成最终的图片中，会尽量保持原图片中的结构内容特征，所以对自动驾驶系统的行为干扰会比较小。

本研究的数据和成果基于文章中展开的研究对各个模型在图像转换性能上对提出的指标展开了定量的分析和比较，希望能对以后从事自动驾驶测试的技术人员，在图像转换技术模型选型上能够给出有价值的参考意见。

\end{conclusions}
